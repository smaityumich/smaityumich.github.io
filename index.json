[{"authors":null,"categories":null,"content":"I am a PhD student in the Department of Statistics at University of Michigan. My current research interest includes transfer learning, high-dimensial statistics, algorithmic fairness, though I\u0026rsquo;m always interested to learn about new topics. There are so many things one can learn in a life-time.\nOn a personal note I love football, cycling, and cooking.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/subha-maity/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/subha-maity/","section":"authors","summary":"I am a PhD student in the Department of Statistics at University of Michigan. My current research interest includes transfer learning, high-dimensial statistics, algorithmic fairness, though I\u0026rsquo;m always interested to learn about new topics.","tags":null,"title":"Subha Maity","type":"authors"},{"authors":["Subha Maity, Debarghya Mukherjee, Mikhail Yurochkin, Yuekai Sun"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"/publication/preprint/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"One of the main barriers to the broader adoption of algorithmic fairness in machine learning is the trade-off between fairness and performance of ML models; many practitioners are unwilling to sacrifice the performance of their ML model for fairness. In this paper, we show that this trade-off may not be necessary. If the algorithmic biases in an ML model are due to sampling biases in the training data, then enforcing algorithmic fairness may improve the performance of the ML model on unbiased test data. We study conditions under which enforcing algorithmic fairness helps practitioners learn the Bayes decision rule for (unbiased) test data from biased training data. We also demonstrate the practical implications of our theoretical results in real-world ML tasks.","tags":["Source Themes"],"title":"There is no trade-off: enforcing fairness can improve accuracy","type":"publication"}]