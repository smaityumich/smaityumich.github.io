[{"authors":null,"categories":null,"content":"I am a PhD student in the Department of Statistics at University of Michigan. My current research interest includes transfer learning, high-dimensial statistics, algorithmic fairness, though I\u0026rsquo;m always interested to learn about new topics. There are so many things one can learn in a life-time.\nOn a personal note I love football, cycling, and cooking.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/subha-maity/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/subha-maity/","section":"authors","summary":"I am a PhD student in the Department of Statistics at University of Michigan. My current research interest includes transfer learning, high-dimensial statistics, algorithmic fairness, though I\u0026rsquo;m always interested to learn about new topics.","tags":null,"title":"Subha Maity","type":"authors"},{"authors":["Subha Maity","Yuekai Sun","Moulinath Banerjee"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607321745,"objectID":"2862fc545785e4c9ce0658c1d5c21896","permalink":"/publication/maity-2020-minimax/","publishdate":"2020-12-07T06:15:45.433178Z","relpermalink":"/publication/maity-2020-minimax/","section":"publication","summary":"We study minimax rates of convergence in the label shift problem. In addition to the usual setting in which the learner only has access to unlabeled examples from the target domain, we also consider the setting in which a small number of labeled examples from the target domain are available to the learner. Our study reveals a difference in the difficulty of the label shift problem in the two settings. We attribute this difference to the availability of data from the target domain to estimate the class conditional distributions in the latter setting. We also show that a distributional matching approach is minimax rate-optimal in the former setting.","tags":[],"title":"Minimax optimal approaches to the label shift problem","type":"publication"},{"authors":["Subha Maity","Debarghya Mukherjee","Mikhail Yurochkin","Yuekai Sun"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607321745,"objectID":"0502fb45acd92946a94fdfba3c839e70","permalink":"/publication/maity-2020-there/","publishdate":"2020-12-07T06:15:45.262533Z","relpermalink":"/publication/maity-2020-there/","section":"publication","summary":"One of the main barriers to the broader adoption of algorithmic fairness in machine learning is the trade-off between fairness and performance of ML models: many practitioners are unwilling to sacrifice the performance of their ML model for fairness. In this paper, we show that this trade-off may not be necessary. If the algorithmic biases in an ML model are due to sampling biases in the training data, then enforcing algorithmic fairness may improve the performance of the ML model on unbiased test data. We study conditions under which enforcing algorithmic fairness helps practitioners learn the Bayes decision rule for (unbiased) test data from biased training data. We also demonstrate the practical implications of our theoretical results in real-world ML tasks.","tags":[],"title":"There is no trade-off: enforcing fairness can improve accuracy","type":"publication"},{"authors":["Subha Maity","Yuekai Sun","Moulinath Banerjee"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607321745,"objectID":"8e6ff4742ac14c5cf51e68d562c635a0","permalink":"/publication/maity-2019-communication/","publishdate":"2020-12-07T06:15:45.677152Z","relpermalink":"/publication/maity-2019-communication/","section":"publication","summary":"We consider the task of meta-analysis in high-dimensional settings in which the data sources we wish to integrate are similar but non-identical. To borrow strength across such heterogeneous data sources, we introduce a global parameter that addresses several identification issues. We also propose a one-shot estimator of the global parameter that preserves the anonymity of the data sources and converges at a rate that depends on the size of the combined dataset. Finally, we demonstrate the benefits of our approach on a large-scale drug treatment dataset involving several different cancer cell lines.","tags":[],"title":"Communication-Efficient Integrative Regression in High-Dimensions","type":"publication"}]